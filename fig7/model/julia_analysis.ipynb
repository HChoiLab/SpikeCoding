{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0dd1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/51cab8e982c5b598eea9c8ceaced4b58d9dd37c9/build.log`\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/9816a3826b0ebf49ab4926e2b18842ad8b5c8f04/build.log`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.build(\"PyPlot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76e8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using MAT\n",
    "# using DelimitedFiles\n",
    "# using Plots\n",
    "using CausalityTools\n",
    "# using LIBSVM\n",
    "# using ScikitLearn\n",
    "# using LaTeXStrings\n",
    "# using Metrics\n",
    "# using Statistics\n",
    "using PyCall\n",
    "np = pyimport(\"numpy\")\n",
    "# using PyPlot\n",
    "# const plt = PyPlot;\n",
    "using Distributions, Random\n",
    "# using Printf\n",
    "using NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56608b2-cac2-4bef-abda-c022c5c8d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isdir(\"model_mutual_info2\")\n",
    "else\n",
    "    mkdir(\"model_mutual_info2\");\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebfd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kvec = [5,6,7,8,9,10]\n",
    "\n",
    "Random.seed!(1234);\n",
    "d = Normal(0,0.0001)\n",
    "td = truncated(d, -Inf, Inf)\n",
    "\n",
    "measure = MIShannon(; base = 2)\n",
    "stim = npzread(\"rawData2/stim.npy\");\n",
    "tf=2000\n",
    "T=50\n",
    "y = StateSpaceSet(stim[1:tf-T])\n",
    "\n",
    "layers = [\"in\",\"E1\",\"B\",\"E2\",\"out\"]\n",
    "# layer = \"out\"\n",
    "\n",
    "numseeds=25\n",
    "for k in kvec\n",
    "    folder = \"model_mutual_info2/k\"*string(k)\n",
    "    println(\"k=\"*string(k))\n",
    "    if isdir(folder)\n",
    "    else\n",
    "        mkdir(folder);\n",
    "    end\n",
    "    for layer in layers\n",
    "#         println(layer)\n",
    "        spks = npzread(\"rawData2/seed0/\"*string(layer)*\"_spks.npy\");\n",
    "        spks = Int.(spks) # timesteps X neuron\n",
    "        num_nrn = size(spks)[2]\n",
    "#         println(num_nrn)\n",
    "        all_cmis = zeros(numseeds,num_nrn)\n",
    "\n",
    "        for seed in 0:numseeds-1\n",
    "            spks = npzread(\"rawData2/seed\"*string(seed)*\"/\"*string(layer)*\"_spks.npy\");\n",
    "            spks = Int.(spks) # timesteps X neuron\n",
    "            num_nrn = size(spks)[2]\n",
    "            T = 50\n",
    "            tf = size(spks)[1]\n",
    "            counts = Int.(zeros(tf-T,num_nrn))\n",
    "\n",
    "            for t in 1:tf-T\n",
    "                sub = spks[t:t+T,:]\n",
    "                counts[t,:] = dropdims(sum(sub, dims=1), dims=1)\n",
    "            end\n",
    "\n",
    "            for nrn in 1:num_nrn\n",
    "                # noise = rand(d,size(counts[:,nrn]))\n",
    "                noise = 0.0001.*randn(size(counts[:,nrn]))\n",
    "                X = StateSpaceSet(counts[:,nrn] .+ noise)\n",
    "                mi = mutualinfo(measure, KSG2(k = k), X, y)\n",
    "                all_cmis[seed+1,nrn] = mi*(mi>0)\n",
    "            end\n",
    "        end\n",
    "        npzwrite(folder*\"/countMI_\"*string(layer)*\".npy\", all_cmis)\n",
    "    end\n",
    "end\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# box = ax.boxplot(all_cmis)\n",
    "# plt.ylim(-0.1,1.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f3d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=4\n",
      "in\n",
      "num_nrn = 48\n",
      "E1\n",
      "num_nrn = 1000\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] getindex",
      "   @ ./tuple.jl:29 [inlined]",
      " [2] iterate",
      "   @ ./tuple.jl:68 [inlined]",
      " [3] iterate",
      "   @ ./iterators.jl:202 [inlined]",
      " [4] estimate(::MIShannon{Shannon{Int64}}, ::KraskovStögbauerGrassberger2{Chebyshev, Chebyshev}, ::StateSpaceSet{1, Float64}, ::StateSpaceSet{1, Float32})",
      "   @ CausalityTools ~/.julia/packages/CausalityTools/alYDd/src/methods/infomeasures/mutualinfo/estimators/KSG2.jl:97",
      " [5] mutualinfo(measure::MIShannon{Shannon{Int64}}, est::KraskovStögbauerGrassberger2{Chebyshev, Chebyshev}, x::StateSpaceSet{1, Float64}, y::StateSpaceSet{1, Float32})",
      "   @ CausalityTools ~/.julia/packages/CausalityTools/alYDd/src/methods/infomeasures/mutualinfo/mutualinfo.jl:173",
      " [6] top-level scope",
      "   @ ./In[4]:54"
     ]
    }
   ],
   "source": [
    "Random.seed!(1234);\n",
    "d = Normal(0,0.0001)\n",
    "td = truncated(d, -Inf, Inf)\n",
    "\n",
    "measure = MIShannon(; base = 2)\n",
    "stim = npzread(\"rawData2/stim.npy\");\n",
    "tf=2000\n",
    "T=50\n",
    "y = StateSpaceSet(stim[1:tf-T])\n",
    "\n",
    "layers = [\"in\",\"E1\",\"B\",\"E2\",\"out\"]\n",
    "# layer = \"out\"\n",
    "\n",
    "k=4\n",
    "\n",
    "folder = \"model_mutual_info2/k\"*string(k)\n",
    "println(\"k=\"*string(k))\n",
    "if isdir(folder)\n",
    "else\n",
    "    mkdir(folder);\n",
    "end\n",
    "\n",
    "num_nrn_vec = [48,1000,10,100,10]\n",
    "\n",
    "nni = 1\n",
    "numseeds=25\n",
    "for layer in layers\n",
    "    println(layer)\n",
    "#     spks = npzread(\"rawData2/seed0/\"*string(layer)*\"_spks.npy\");\n",
    "#     spks = Int.(spks) # timesteps X neuron\n",
    "#     num_nrn = size(spks)[2]\n",
    "#     println(num_nrn)\n",
    "#     all_cmis = zeros(numseeds,num_nrn)\n",
    "    num_nrn = num_nrn_vec[nni]\n",
    "    println(\"num_nrn = \"*string(num_nrn))\n",
    "    all_cmis = zeros(numseeds,num_nrn)\n",
    "    for seed in 0:numseeds-1\n",
    "        spks = npzread(\"rawData2/seed\"*string(seed)*\"/\"*string(layer)*\"_spks.npy\");\n",
    "        spks = Int.(spks) # timesteps X neuron\n",
    "        num_nrn = size(spks)[2]\n",
    "        T = 50\n",
    "        tf = size(spks)[1]\n",
    "        counts = Int.(zeros(tf-T,num_nrn))\n",
    "    \n",
    "        for t in 1:tf-T\n",
    "            sub = spks[t:t+T,:]\n",
    "            counts[t,:] = dropdims(sum(sub, dims=1), dims=1)\n",
    "        end\n",
    "    \n",
    "        for nrn in 1:num_nrn\n",
    "            # noise = rand(d,size(counts[:,nrn]))\n",
    "            noise = 0.0001.*randn(size(counts[:,nrn]))\n",
    "            X = StateSpaceSet(counts[:,nrn] .+ noise)\n",
    "            mi = mutualinfo(measure, KSG2(k = k), X, y)\n",
    "            all_cmis[seed+1,nrn] = mi*(mi>0)\n",
    "        end\n",
    "    end\n",
    "    npzwrite(folder*\"/countMI_\"*string(layer)*\".npy\", all_cmis)\n",
    "    nni += 1\n",
    "end\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# box = ax.boxplot(all_cmis)\n",
    "# plt.ylim(-0.1,1.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba33653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=10\n",
      "in\n",
      "48\n",
      "E1\n",
      "1000\n",
      "B\n",
      "10\n",
      "E2\n",
      "100\n",
      "out\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(1234);\n",
    "d = Normal(0,0.0001)\n",
    "td = truncated(d, -Inf, Inf)\n",
    "\n",
    "measure = MIShannon(; base = 2)\n",
    "stim = npzread(\"rawData2/stim.npy\");\n",
    "tf=2000\n",
    "T=50\n",
    "y = StateSpaceSet(stim[1:tf-T])\n",
    "\n",
    "layers = [\"in\",\"E1\",\"B\",\"E2\",\"out\"]\n",
    "# layer = \"out\"\n",
    "\n",
    "k=10\n",
    "\n",
    "folder = \"model_mutual_info2/k\"*string(k)\n",
    "println(\"k=\"*string(k))\n",
    "if isdir(folder)\n",
    "else\n",
    "    mkdir(folder);\n",
    "end\n",
    "\n",
    "numseeds=25\n",
    "for layer in layers\n",
    "    println(layer)\n",
    "    spks = npzread(\"rawData2/seed0/\"*string(layer)*\"_spks.npy\");\n",
    "    spks = Int.(spks) # timesteps X neuron\n",
    "    num_nrn = size(spks)[2]\n",
    "    println(num_nrn)\n",
    "    all_cmis = zeros(numseeds,num_nrn)\n",
    "    \n",
    "    for seed in 0:numseeds-1\n",
    "        spks = npzread(\"rawData2/seed\"*string(seed)*\"/\"*string(layer)*\"_spks.npy\");\n",
    "        spks = Int.(spks) # timesteps X neuron\n",
    "        num_nrn = size(spks)[2]\n",
    "        T = 50\n",
    "        tf = size(spks)[1]\n",
    "        counts = Int.(zeros(tf-T,num_nrn))\n",
    "    \n",
    "        for t in 1:tf-T\n",
    "            sub = spks[t:t+T,:]\n",
    "            counts[t,:] = dropdims(sum(sub, dims=1), dims=1)\n",
    "        end\n",
    "    \n",
    "        for nrn in 1:num_nrn\n",
    "            # noise = rand(d,size(counts[:,nrn]))\n",
    "            noise = 0.0001.*randn(size(counts[:,nrn]))\n",
    "            X = StateSpaceSet(counts[:,nrn] .+ noise)\n",
    "            mi = mutualinfo(measure, KSG2(k = k), X, y)\n",
    "            all_cmis[seed+1,nrn] = mi*(mi>0)\n",
    "        end\n",
    "    end\n",
    "    npzwrite(folder*\"/countMI_\"*string(layer)*\".npy\", all_cmis)\n",
    "end\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# box = ax.boxplot(all_cmis)\n",
    "# plt.ylim(-0.1,1.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234);\n",
    "d = Normal(0,0.0001)\n",
    "td = truncated(d, -Inf, Inf)\n",
    "\n",
    "measure = MIShannon(; base = 2)\n",
    "stim = npzread(\"rawData/stim.npy\");\n",
    "tf=1000\n",
    "T=50\n",
    "y = StateSpaceSet(stim[1:tf-T])\n",
    "\n",
    "layers = [\"in\",\"E1\",\"B\",\"E2\",\"out\"]\n",
    "# layer = \"out\"\n",
    "\n",
    "numseeds=25\n",
    "for layer in layers\n",
    "    println(layer)\n",
    "    spks = npzread(\"rawData/seed0/\"*string(layer)*\"_spks.npy\");\n",
    "    spks = Int.(spks) # timesteps X neuron\n",
    "    num_nrn = size(spks)[2]\n",
    "    println(num_nrn)\n",
    "    all_cmis = zeros(numseeds,num_nrn)\n",
    "    \n",
    "    for seed in 0:numseeds-1\n",
    "        spks = npzread(\"rawData/seed\"*string(seed)*\"/\"*string(layer)*\"_spks.npy\");\n",
    "        spks = Int.(spks) # timesteps X neuron\n",
    "        num_nrn = size(spks)[2]\n",
    "        T = 50\n",
    "        tf = size(spks)[1]\n",
    "        counts = Int.(zeros(tf-T,num_nrn))\n",
    "    \n",
    "        for t in 1:tf-T\n",
    "            sub = spks[t:t+T,:]\n",
    "            counts[t,:] = dropdims(sum(sub, dims=1), dims=1)\n",
    "        end\n",
    "    \n",
    "        for nrn in 1:num_nrn\n",
    "            # noise = rand(d,size(counts[:,nrn]))\n",
    "            noise = 0.0001.*randn(size(counts[:,nrn]))\n",
    "            X = StateSpaceSet(counts[:,nrn] .+ noise)\n",
    "            mi = mutualinfo(measure, KSG2(k = 3), X, y)\n",
    "            all_cmis[seed+1,nrn] = mi*(mi>0)\n",
    "        end\n",
    "    end\n",
    "    npzwrite(\"model_mutual_info/countMI_\"*string(layer)*\".npy\", all_cmis)\n",
    "end\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# box = ax.boxplot(all_cmis)\n",
    "# plt.ylim(-0.1,1.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1366e59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=10\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(1234);\n",
    "measure = MIShannon(; base = 2)\n",
    "\n",
    "stim = npzread(\"rawData2/stim.npy\");\n",
    "\n",
    "layers = [\"in\",\"E1\",\"B\",\"E2\",\"out\"]\n",
    "num_nrns_vec = [48,1000,10,100,10] # number of neurons in each layer\n",
    "numLayers = length(layers)\n",
    "\n",
    "tf=2000\n",
    "T=50\n",
    "\n",
    "k = 10\n",
    "\n",
    "# for k in kvec\n",
    "folder = \"model_mutual_info2/k\"*string(k)\n",
    "if isdir(folder)\n",
    "else\n",
    "    mkdir(folder);\n",
    "end\n",
    "println(\"k=\"*string(k))\n",
    "    \n",
    "for li in 1:numLayers\n",
    "    layer = layers[li]\n",
    "    num_nrns = num_nrns_vec[li]\n",
    "#         println(layer)\n",
    "    numseeds=25\n",
    "    num_nrns=10\n",
    "    all_tmis=zeros(numseeds,num_nrns)\n",
    "\n",
    "    for seed in 0:numseeds-1\n",
    "        out_spks = npzread(\"rawData2/seed\"*string(seed)*\"/\"*layer*\"_spks.npy\");\n",
    "        spks = Int.(out_spks) # timesteps X neuron\n",
    "        for nrn_idx in 1:num_nrns\n",
    "            spks_nrn1 = spks[:,nrn_idx]\n",
    "            counts = Int.(zeros(tf-T))\n",
    "            for t in 1:tf-T\n",
    "                sub = spks_nrn1[t:t+T]\n",
    "                counts[t] = sum(sub)\n",
    "            end\n",
    "\n",
    "            # get spike count probability distribution \"pcount\"\n",
    "            histstuff=plt.hist(counts,bins=np.arange(0.5,maximum(counts)+1,1)) # exclude spike count = 0\n",
    "            plt.close()\n",
    "            num_obs = Int.(histstuff[1]) # number of observations of each spike count\n",
    "            bin_edges = histstuff[2]\n",
    "            pcount = num_obs./sum(num_obs)\n",
    "\n",
    "            # create dictionary to store spike timing distributions conditioned on spike count\n",
    "            spk_timing_dict = Dict()\n",
    "            y_dict = Dict() # for storing stimuli conditioned on spike count\n",
    "            for spk_count in 1:maximum(counts)\n",
    "                key = \"spk_count_\"*string(spk_count)\n",
    "                counter_key = \"counter_\"*string(spk_count)\n",
    "                spk_timing_dict[counter_key] = 1\n",
    "                value = zeros(num_obs[spk_count],spk_count)\n",
    "                spk_timing_dict[key] = value\n",
    "                yvalue = zeros(num_obs[spk_count])\n",
    "                y_dict[key] = yvalue\n",
    "            end\n",
    "\n",
    "\n",
    "            for t in 1:tf-T\n",
    "                sub = spks_nrn1[t:t+T]\n",
    "                spk_count = sum(sub)\n",
    "                y_this_ws = stim[t] # stim at this wingstroke\n",
    "                if spk_count < 1\n",
    "                    continue\n",
    "                else\n",
    "                    strokes_nonans=[]\n",
    "                    for i in 1:length(sub)\n",
    "                        if sub[i] == 1\n",
    "                            push!(strokes_nonans,i)\n",
    "                        end\n",
    "                    end\n",
    "                    key = \"spk_count_\"*string(spk_count)\n",
    "                    counter_key = \"counter_\"*string(spk_count)\n",
    "                    idx = spk_timing_dict[counter_key]\n",
    "                    spk_timing_dict[key][idx,:] = strokes_nonans\n",
    "                    y_dict[key][idx] = y_this_ws\n",
    "                    spk_timing_dict[counter_key] += 1\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # compute timing mutual information\n",
    "            tmi=0\n",
    "            for spk_count in 1:maximum(counts)\n",
    "                key = \"spk_count_\"*string(spk_count)\n",
    "                Stpre = spk_timing_dict[key]\n",
    "                if size(Stpre)[1] < size(Stpre)[2]\n",
    "                    continue\n",
    "                else\n",
    "                    try\n",
    "                        noise = 0.001*randn(size(Stpre))\n",
    "                        St = StateSpaceSet(Stpre .+ noise)\n",
    "                        tau = StateSpaceSet(y_dict[key])\n",
    "                        mi = mutualinfo(measure, KSG2(k = k), St, tau)\n",
    "                        tmi += pcount[spk_count]*mi*(mi>0)\n",
    "                    catch\n",
    "                        println(\"BoundsError\")\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "    #         print(string(tmi)*\" bits\")\n",
    "            all_tmis[seed+1,nrn_idx] = tmi\n",
    "        end\n",
    "    end\n",
    "    npzwrite(folder*\"/timingMI_\"*string(layer)*\".npy\", all_tmis)\n",
    "end\n",
    "println(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234);\n",
    "measure = MIShannon(; base = 2)\n",
    "\n",
    "stim = npzread(\"rawData/stim.npy\");\n",
    "\n",
    "layers = [\"in\",\"E1\",\"B\",\"E2\",\"out\"]\n",
    "num_nrns_vec = [48,1000,10,100,10] # number of neurons in each layer\n",
    "numLayers = length(layers)\n",
    "\n",
    "tf=1000\n",
    "T=50\n",
    "\n",
    "for li in 1:numLayers\n",
    "    layer = layers[li]\n",
    "    num_nrns = num_nrns_vec[li]\n",
    "    println(layer)\n",
    "    numseeds=25\n",
    "    num_nrns=10\n",
    "    all_tmis=zeros(numseeds,num_nrns)\n",
    "    \n",
    "    for seed in 0:numseeds-1\n",
    "        out_spks = npzread(\"rawData/seed\"*string(seed)*\"/\"*layer*\"_spks.npy\");\n",
    "        spks = Int.(out_spks) # timesteps X neuron\n",
    "        for nrn_idx in 1:num_nrns\n",
    "            spks_nrn1 = spks[:,nrn_idx]\n",
    "            counts = Int.(zeros(tf-T))\n",
    "            for t in 1:tf-T\n",
    "                sub = spks_nrn1[t:t+T]\n",
    "                counts[t] = sum(sub)\n",
    "            end\n",
    "    \n",
    "            # get spike count probability distribution \"pcount\"\n",
    "            histstuff=plt.hist(counts,bins=np.arange(0.5,maximum(counts)+1,1)) # exclude spike count = 0\n",
    "            plt.close()\n",
    "            num_obs = Int.(histstuff[1]) # number of observations of each spike count\n",
    "            bin_edges = histstuff[2]\n",
    "            pcount = num_obs./sum(num_obs)\n",
    "    \n",
    "            # create dictionary to store spike timing distributions conditioned on spike count\n",
    "            spk_timing_dict = Dict()\n",
    "            y_dict = Dict() # for storing stimuli conditioned on spike count\n",
    "            for spk_count in 1:maximum(counts)\n",
    "                key = \"spk_count_\"*string(spk_count)\n",
    "                counter_key = \"counter_\"*string(spk_count)\n",
    "                spk_timing_dict[counter_key] = 1\n",
    "                value = zeros(num_obs[spk_count],spk_count)\n",
    "                spk_timing_dict[key] = value\n",
    "                yvalue = zeros(num_obs[spk_count])\n",
    "                y_dict[key] = yvalue\n",
    "            end\n",
    "    \n",
    "    \n",
    "            for t in 1:tf-T\n",
    "                sub = spks_nrn1[t:t+T]\n",
    "                spk_count = sum(sub)\n",
    "                y_this_ws = stim[t] # stim at this wingstroke\n",
    "                if spk_count < 1\n",
    "                    continue\n",
    "                else\n",
    "                    strokes_nonans=[]\n",
    "                    for i in 1:length(sub)\n",
    "                        if sub[i] == 1\n",
    "                            push!(strokes_nonans,i)\n",
    "                        end\n",
    "                    end\n",
    "                    key = \"spk_count_\"*string(spk_count)\n",
    "                    counter_key = \"counter_\"*string(spk_count)\n",
    "                    idx = spk_timing_dict[counter_key]\n",
    "                    spk_timing_dict[key][idx,:] = strokes_nonans\n",
    "                    y_dict[key][idx] = y_this_ws\n",
    "                    spk_timing_dict[counter_key] += 1\n",
    "                end\n",
    "            end\n",
    "    \n",
    "            # compute timing mutual information\n",
    "            tmi=0\n",
    "            for spk_count in 1:maximum(counts)\n",
    "                key = \"spk_count_\"*string(spk_count)\n",
    "                Stpre = spk_timing_dict[key]\n",
    "                if size(Stpre)[1] < size(Stpre)[2]\n",
    "                    continue\n",
    "                else\n",
    "                    try\n",
    "                        noise = 0.0001*randn(size(Stpre))\n",
    "                        St = StateSpaceSet(Stpre .+ noise)\n",
    "                        tau = StateSpaceSet(y_dict[key])\n",
    "                        mi = mutualinfo(measure, KSG2(k = 3), St, tau)\n",
    "                        tmi += pcount[spk_count]*mi*(mi>0)\n",
    "                    catch\n",
    "                        println(\"BoundsError\")\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "    \n",
    "    #         print(string(tmi)*\" bits\")\n",
    "            all_tmis[seed+1,nrn_idx] = tmi\n",
    "        end\n",
    "    end\n",
    "    npzwrite(\"model_mutual_info/timingMI_\"*layer*\".npy\", all_tmis)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
